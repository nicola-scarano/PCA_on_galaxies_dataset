# -*- coding: utf-8 -*-
"""PCA_homework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NVt1D-oo5QUhWFXV2S_3-WEIrwqf4fsZ

# Principal Component Analysis on a galaxy dataset

## Part 1: Extraction of the Working Dataset
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/Computational_algebra

"""####Import of the necessary libraries"""

from sklearn import datasets
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import pyplot
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error

"""#### Load the dataset"""

COMBO17 = pd.read_csv("./COMBO17.csv")

"""####Selection of a sample from the original dataset"""

np.random.seed(287908)
train_index = np.random.choice(COMBO17.index, 2500, replace=False)

"""#### Creation and saving of two sub-dataset """

# Creation of COMBO17pca_287908 and COMBO17eval_287908
COMBO17pca_287908 = COMBO17.loc[train_index]
COMBO17.drop(train_index)
COMBO17eval_287908 = COMBO17
COMBO17eval_287908.dropna(inplace=True)
COMBO17pca_287908.dropna(inplace=True)

# Saving
COMBO17eval_287908.to_csv('./COMBO17eval_287908.csv', sep=',')
COMBO17pca_287908.to_csv('./COMBO17pca_287908.csv', sep=',')

"""## Part 2: PCA

### Data cleaning
"""

#We compute the PCA on all the dataset except for the feature related with the RedShift
COMBO17pca_287908_Mcz = COMBO17pca_287908["Mcz"]
COMBO17eval_287908_Mcz = COMBO17eval_287908["Mcz"]
COMBO17pca_287908.drop(columns=["Nr","Mcz", "e.Mcz", "MCzml", "chi2red"], inplace=True)
COMBO17eval_287908.drop(columns=["Nr","Mcz", "e.Mcz", "MCzml", "chi2red"], inplace=True)
feature_PCA = COMBO17pca_287908.columns

feature_PCA[:25]

"""### Data transformation: normalization

#### Box plot of dataset's features before normalization
"""

fig, ax = pyplot.subplots(figsize=(20,10))
graph = sns.boxplot(data = COMBO17pca_287908.iloc[:, :20])
graph.axes.set_title("Dataset's features distribution \nbefore normalization ",fontsize=25)
graph.set_xlabel("feature",fontsize=20)
graph.set_ylabel("value",fontsize=20)
graph.tick_params(labelsize = 12)
plt.grid()
plt.savefig('before_norm.png', dpi = 300)

"""#### Normalization of the dataset's feature"""

scaler = StandardScaler()
scaler.fit(COMBO17pca_287908.values)
norm = scaler.transform(COMBO17pca_287908.values)
norm2 = scaler.transform(COMBO17eval_287908.values)

COMBO17pca_287908 = pd.DataFrame(data=norm, columns=feature_PCA)
COMBO17eval_287908 = pd.DataFrame(data=norm2, columns=feature_PCA)

step =10
a = 'reconstruction'+str(step)
a

"""#### Box plot of dataset's features after normalization"""

df = pd.DataFrame(data=norm[:, :20], columns=feature_PCA[:20])
fig, ax = pyplot.subplots(figsize=(20,10))
graph = sns.boxplot(data = df)
graph.axes.set_title("Dataset's features distribution \nafter normalization ",fontsize=25)
graph.set_xlabel("feature",fontsize=20)
graph.set_ylabel("value",fontsize=20)
graph.tick_params(labelsize = 12)
plt.grid()
plt.savefig('after_norm.png', dpi = 300)

"""### Qualitative evaluation of the PCA using graphs

#### PCA with 10 components on the dataset
"""

#select m PC, write in the reposrt the motivation to the choice. 
#Report in the report all the trial that we do in order to select those

# Creation of the PCA module to use. 
# We choose n_components = means that 
# The PCA is applied to the covariance matrix of our dataset
pca_trial = PCA(n_components = 10)

# PCA module fitting of out set
pca_trial.fit(COMBO17pca_287908)
COMBO17pca_287908_ = pca_trial.transform(COMBO17pca_287908)
COMBO17eval_287908_ = pca_trial.transform(COMBO17eval_287908)

"""#### Computation of three variables that will be used to generate graphs"""

# Array of percentace of explained variance by component  
percentage_variance = np.array(pca_trial.explained_variance_ratio_)

# Array of variance explained by component
variances = np.array(pca_trial.explained_variance_)

# Array of cumulative explained variance by component 
cum_variances = []
for i in range(len(percentage_variance)):
  cum_variances.append(sum(percentage_variance[0:i+1]))

"""#### Graph rapresenting the cumulative percentage of explained variance"""

fig, ax = pyplot.subplots(figsize=(10,7))
graph = sns.barplot(ax = ax, y = cum_variances, x = ["PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8", "PC9", "PC10"], palette = "viridis")
graph.axhline(0.75, color = 'red')
graph.axes.set_title("Cum. % of expl. variance",fontsize=30)
graph.set_xlabel("Principal component",fontsize=20)
graph.set_ylabel("% of expl. variance",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)

#The plot is shown
plt.show()
fig.savefig('cum.png', dpi=300)

"""#### Graph rapresenting the percentage of explained variance by component"""

fig, ax = pyplot.subplots(figsize=(10,7))
graph = sns.barplot(ax = ax, y = percentage_variance, x = ["PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8", "PC9", "PC10"], palette = "viridis")
graph.axhline(0.04, color = 'red')
graph.axes.set_title("% of expl. variance by component",fontsize=30)
graph.set_xlabel("Principal component",fontsize=20)
graph.set_ylabel("% of expl. variance",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)

#The plot is shown
fig.savefig('var.png', dpi=300)

"""#### Interpretation of the principal component"""

# The covariance matrix allow us to have explain more data variance with less feature, 
# so from now on we will show only the result obtained with the PCA applied to the covariance matrix   
# Now let us see how the components of our PC are distribuited

# first PC component distribution
PC1_comp = pca_trial.components_[0,:]
PC1_comp
fig, ax = plt.subplots(1,1)
ax.set_title('First principal component',  fontsize=25)
fig.set_size_inches(17,8)
feature_num = list(str(el) for el in np.argsort(PC1_comp)[::-1])
ax.bar(feature_num, np.sort(PC1_comp)[::-1])
ax.set_xlabel('Feature number',  fontsize=17)
ax.set_ylabel('Value', fontsize=17)

fig.savefig('pc1.png', dpi=300)

# second PC component distribution
PC2_comp = pca_trial.components_[1,:]
PC2_comp
fig, ax = plt.subplots(1,1)
ax.set_title('Second principal component',  fontsize=25)
fig.set_size_inches(17,8)
feature_num = list(str(el) for el in np.argsort(PC2_comp)[::-1])
ax.bar(feature_num, np.sort(PC2_comp)[::-1])
ax.set_xlabel('Feature number',  fontsize=17)
ax.set_ylabel('Value', fontsize=17)

fig.savefig('pc2.png', dpi=300)

# third component
PC3_comp = pca_trial.components_[2,:]
PC3_comp
fig, ax = plt.subplots(1,1)
ax.set_title('Third principal component',  fontsize=25)
fig.set_size_inches(17,8)
feature_num = list(str(el) for el in np.argsort(PC3_comp)[::-1])
ax.bar(feature_num, np.sort(PC3_comp)[::-1])
ax.set_xlabel('Feature number',  fontsize=17)
ax.set_ylabel('Value', fontsize=17)

fig.savefig('pc3.png', dpi=300)

# fourth component
PC4_comp = pca_trial.components_[3,:]
PC4_comp
fig, ax = plt.subplots(1,1)
ax.set_title('Fourth principal component',  fontsize=25)
fig.set_size_inches(17,8)
feature_num = list(str(el) for el in np.argsort(PC4_comp)[::-1])
ax.bar(feature_num, np.sort(PC4_comp)[::-1])
ax.set_xlabel('Feature number',  fontsize=17)
ax.set_ylabel('Value', fontsize=17)

fig.savefig('pc4.png', dpi=300)

"""## Part 3: scatter plot to visualize on the dataset in the principal component space

#### The dataset in the space of the first two pricipal component
"""

mask = ((COMBO17pca_287908_[:,0]<28) & (COMBO17pca_287908_[:,0]>-11) & (COMBO17pca_287908_[:,1]<10) & (COMBO17pca_287908_[:,1]>-5))
c = np.array(COMBO17pca_287908_Mcz[mask])

fig, ax = plt.subplots()
ax.set_facecolor('white')
plt.grid(color='grey', linestyle='solid')
fig.set_size_inches(13,10)
ax.scatter(COMBO17pca_287908_[mask][:,0], COMBO17pca_287908_[mask][:,1], c=c)

ax.set_xlabel(r'Principal component 1', fontsize=20)
ax.set_ylabel(r'Principal component 2', fontsize=20)
ax.set_title('Distribution of the Galaxies \nin the PC1-PC2 space',fontsize=30)

ax.grid(True)
fig.tight_layout()

plt.show()

"""#### The dataset in the space of the first three pricipal component"""

mask = ((COMBO17pca_287908_[:,1]<2) & (COMBO17pca_287908_[:,0]>-11) & (COMBO17pca_287908_[:,0]<8) & (COMBO17pca_287908_[:,1]>-2))
c = np.array(COMBO17pca_287908_Mcz[mask])

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.set_facecolor('xkcd:white')
plt.grid(color='w', linestyle='solid')
fig.set_size_inches(13,10)
ax.scatter(COMBO17pca_287908_[mask][:,0], COMBO17pca_287908_[mask][:,1], c=c)

ax.set_xlabel(r'Principal component 1', fontsize=17)
ax.set_ylabel(r'Principal component 2', fontsize=17)
ax.set_zlabel(r'Principal component 3', fontsize=17)
ax.set_title('Distribution of the Galaxies \nin the PC1-PC2-PC3 space',fontsize=25)

fig.tight_layout()

plt.show()

"""## Part 4: K Nearest neighboorhood"""

MAE_sequence = []
MRE_sequence = []

max_comp = 20

for n_comp in range(1,max_comp +1):
  pca_kNN = PCA(n_components = n_comp)

  # PCA module fitting of out set
  pca_kNN.fit(COMBO17pca_287908)
  COMBO17pca_287908_kNN = pca_kNN.transform(COMBO17pca_287908)
  COMBO17eval_287908_kNN = pca_kNN.transform(COMBO17eval_287908)
  COMBO17pca_287908_kNN.shape

  neigh = KNeighborsRegressor(n_neighbors=1, weights = "uniform")
  X = COMBO17pca_287908_kNN
  y = COMBO17pca_287908_Mcz
  neigh.fit(X, y)
  Mcz_predict = neigh.predict(COMBO17eval_287908_kNN)
  mean_absolute_error_ = mean_absolute_error(Mcz_predict, COMBO17eval_287908_Mcz)
  mean_relative_error_ = sum(abs(Mcz_predict-np.array(COMBO17eval_287908_Mcz))/abs(np.array(COMBO17eval_287908_Mcz)))/len(Mcz_predict)
  MAE_sequence.append(mean_absolute_error_)
  MRE_sequence.append(mean_relative_error_)
print("Best MAE:", min(MAE_sequence), "using", np.argmin(MAE_sequence)+1," components", "\nBest MRE:",  min(MRE_sequence), "using", np.argmin(MRE_sequence)+1," components")

X_ticks = np.linspace(1,max_comp ,max_comp)
Y_ticks = np.linspace(0,1)

fig, ax = pyplot.subplots(figsize=(10,7))

ax.set_xticks(X_ticks)
ax.set_yticks(Y_ticks)

df = pd.DataFrame(np.transpose(np.array([MAE_sequence, MRE_sequence])), columns=["MAE", "MRE"], index = range(1,max_comp+1))
graph = sns.lineplot(ax = ax, data = df, markers=True, dashes=False)
graph.axes.set_title("Mean absolute error and mean relative error \nfor different PCA reductions ",fontsize=30)
graph.set_xlabel("Number of component",fontsize=20)
graph.set_ylabel("MAE",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)
plt.setp(ax.get_legend().get_texts(), fontsize='20') # for legend text
#The plot is shown
fig.savefig('knn.png', dpi=300)